"""Functions to calculate principal graph"""

import numpy as np
import pandas as pd
import elpigraph
import networkx as nx
from sklearn.cluster import SpectralClustering, AffinityPropagation, KMeans
from sklearn.metrics.pairwise import pairwise_distances, euclidean_distances

from .._settings import settings


def learn_graph(
    adata,
    method="principal_curve",
    obsm="X_dr",
    layer=None,
    n_nodes=30,
    epg_lambda=0.01,
    epg_mu=0.1,
    epg_alpha=0,
    use_seed=True,
    n_jobs=None,
    **kwargs,
):
    """Learn principal graph

    Parameters
    ----------
    adata: `AnnData`
        Anndata object.
    method: `str`, (default: 'principal_curve');
        Method used to calculate the graph.
    obsm: `str`, optional (default: 'X_dr')
        The multi-dimensional annotation of observations used to learn the graph
    layer: `str`, optional (default: None)
        The layer used to learn the graph
    use_seed: bool
        Whether to use the seed graph in adata.uns['seed_epg'] generated by st.seed_graph. 
        If True, ignores obsm and layer parameters
    **kwargs:
        Additional arguments to each method

    Returns
    -------
    updates `adata.uns['epg']` with the following field.
    conn: `sparse matrix` (`.uns['epg']['conn']`)
        A connectivity sparse matrix.
    node_pos: `array` (`.uns['epg']['node_pos']`)
        Node positions.
    """

    assert method in ["principal_curve", "principal_tree", "principal_circle"], (
        "`method` must be one of "
        "['principal_curve','principal_tree','principal_circle']"
    )

    if use_seed:
        if "seed_epg" not in adata.uns:
            raise ValueError(
                f"could not find 'seed_epg' in `adata.uns. Please run st.tl.seed_graph"
            )
        if n_nodes <= len(adata.uns["seed_epg"]["node_pos"]):
            raise ValueError(
                f"The seed graph already has at least {n_nodes} nodes. Please run st.tl.learn_graph with higher n_nodes"
            )
        kwargs["InitNodePositions"] = adata.uns["seed_epg"]["node_pos"]
        kwargs["InitEdges"] = adata.uns["seed_epg"]["edge"]
        if adata.uns["seed_epg"]["params"]["obsm"] is not None:
            mat = adata.obsm[adata.uns["seed_epg"]["params"]["obsm"]]
        elif adata.uns["seed_epg"]["params"]["layer"] is not None:
            mat = adata.obsm[adata.uns["seed_epg"]["params"]["layer"]]
        else:
            print("Learning the graph on adata.X")
            mat = adata.X
    else:
        kwargs["InitNodePositions"] = None
        kwargs["InitEdges"] = None
        if sum(list(map(lambda x: x is not None, [layer, obsm]))) == 2:
            raise ValueError("Only one of `layer` and `obsm` can be used")
        elif obsm is not None:
            if obsm in adata.obsm:
                mat = adata.obsm[obsm]
            else:
                raise ValueError(f"could not find {obsm} in `adata.obsm`")
        elif layer is not None:
            if layer in adata.layers:
                mat = adata.layers[layer]
            else:
                raise ValueError(f"could not find {layer} in `adata.layers`")
        else:
            mat = adata.X

    if n_jobs is None:
        n_jobs = settings.n_jobs

    if method == "principal_curve":
        dict_epg = elpigraph.computeElasticPrincipalCurve(
            X=mat,
            NumNodes=n_nodes,
            n_cores=n_jobs,
            Do_PCA=False,
            CenterData=False,
            Lambda=epg_lambda,
            Mu=epg_mu,
            alpha=epg_alpha,
            **kwargs,
        )[0]
    if method == "principal_tree":
        dict_epg = elpigraph.computeElasticPrincipalTree(
            X=mat,
            NumNodes=n_nodes,
            n_cores=n_jobs,
            Do_PCA=False,
            CenterData=False,
            Lambda=epg_lambda,
            Mu=epg_mu,
            alpha=epg_alpha,
            **kwargs,
        )[0]
    if method == "principal_circle":
        dict_epg = elpigraph.computeElasticPrincipalCircle(
            X=mat,
            NumNodes=n_nodes,
            n_cores=n_jobs,
            Do_PCA=False,
            CenterData=False,
            Lambda=epg_lambda,
            Mu=epg_mu,
            alpha=epg_alpha,
            **kwargs,
        )[0]

    adata.uns["epg"] = dict()
    adata.uns["epg"]["node_pos"] = dict_epg["NodePositions"]
    adata.uns["epg"]["edge"] = dict_epg["Edges"][0]
    adata.uns["epg"]["params"] = {
        "method": method,
        "obsm": obsm,
        "layer": layer,
        "n_nodes": n_nodes,
        "epg_lamba": epg_lambda,
        "epg_mu": epg_mu,
        "epg_alpha": epg_alpha,
        "use_seed": use_seed,
    }
    _store_graph_attributes(adata, mat, key="epg")


def seed_graph(
    adata,
    obsm="X_dr",
    layer=None,
    clustering="kmeans",
    damping=0.75,
    pref_perc=50,
    n_clusters=10,
    max_n_clusters=200,
    n_neighbors=50,
    nb_pct=None,
):

    """Seeding the initial elastic principal graph.
    
    Parameters
    ----------
    adata: AnnData
        Annotated data matrix.
    obsm: `str`, optional (default: 'X_dr')
        The multi-dimensional annotation of observations used to learn the graph
    layer: `str`, optional (default: None)
        The layer used to learn the graph
    init_nodes_pos: `array`, shape = [n_nodes,n_dimension], optional (default: `None`)
        initial node positions
    init_edges: `array`, shape = [n_edges,2], optional (default: `None`)
        initial edges, all the initial nodes should be included in the tree structure
    clustering: `str`, optional (default: 'kmeans')
        Choose from {{'ap','kmeans','sc'}}
        clustering method used to infer the initial nodes.
        'ap' affinity propagation
        'kmeans' K-Means clustering
        'sc' spectral clustering
    damping: `float`, optional (default: 0.75)
        Damping factor (between 0.5 and 1) for affinity propagation.
    pref_perc: `int`, optional (default: 50)
        Preference percentile (between 0 and 100). The percentile of the input similarities for affinity propagation.
    n_clusters: `int`, optional (default: 10)
        Number of clusters (only valid once 'clustering' is specificed as 'sc' or 'kmeans').
    max_n_clusters: `int`, optional (default: 200)
        The allowed maximum number of clusters for 'ap'.
    n_neighbors: `int`, optional (default: 50)
        The number of neighbor cells used for spectral clustering.
    nb_pct: `float`, optional (default: None)
        The percentage of neighbor cells (when sepcified, it will overwrite n_neighbors).
    use_vis: `bool`, optional (default: False)
        If True, the manifold learnt from st.plot_visualization_2D() will replace the manifold learnt from st.dimension_reduction().
        The principal graph will be learnt in the new manifold.
    Returns
    -------
    updates `adata` with the following fields.
    adata.obs: `pandas.core.frame.DataFrame` (`adata.obs`)
        Update adata.obs with adding the columns of current root_node_pseudotime and removing the previous ones.  
    clustering: `pandas.core.series.Series` (`adata.obs['clustering']`,dtype `str`)
        Array of dim (number of samples) that stores the clustering labels ('0', '1', â€¦) for each cell.      
    epg : `networkx.classes.graph.Graph` (`adata.uns['epg']`)
        Elastic principal graph structure. It contains node attributes ('pos')
    flat_tree : `networkx.classes.graph.Graph` (`adata.uns['flat_tree']`)
        An abstract of elastic principle graph structure by only keeping leaf nodes and branching nodes. 
        It contains node attribtutes ('pos','label') and edge attributes ('nodes','id','len','color').
    seed_epg : `networkx.classes.graph.Graph` (`adata.uns['epg']`)
        Store seeded elastic principal graph structure
    seed_flat_tree : `networkx.classes.graph.Graph` (`adata.uns['flat_tree']`)
        Store seeded flat_tree
    Notes
    -------
    The default procedure is fast and good enough when seeding structure in low-dimensional space.
    when seeding structure in high-dimensional space, it's strongly recommended to use 'infer_initial_structure' to get the initial node positions and edges
    """

    print("Seeding initial elastic principal graph...")

    if sum(list(map(lambda x: x is not None, [layer, obsm]))) == 2:
        raise ValueError("Only one of `layer` and `obsm` can be used")
    elif obsm is not None:
        if obsm in adata.obsm:
            mat = adata.obsm[obsm]
            adata.uns["seed"] = obsm
        else:
            raise ValueError(f"could not find {obsm} in `adata.obsm`")
    elif layer is not None:
        if layer in adata.layers:
            mat = adata.layers[layer]
            adata.uns["seed"] = obsm
        else:
            raise ValueError(f"could not find {layer} in `adata.layers`")
    else:
        mat = adata.X

    if nb_pct != None:
        n_neighbors = int(np.around(mat.shape[0] * nb_pct))

    print("Clustering...")
    if clustering == "ap":
        print("Affinity propagation ...")
        ap = AffinityPropagation(
            damping=damping,
            random_state=42,
            preference=np.percentile(
                -euclidean_distances(mat, squared=True), pref_perc
            ),
        ).fit(mat)
        # ap = AffinityPropagation(damping=damping).fit(mat)
        if ap.cluster_centers_.shape[0] > max_n_clusters:
            print("The number of clusters is " + str(ap.cluster_centers_.shape[0]))
            print(
                "Too many clusters are generated, please lower pref_perc or increase damping and retry it"
            )
            return
        cluster_labels = ap.labels_
        init_nodes_pos = ap.cluster_centers_
        epg_nodes_pos = init_nodes_pos
    elif clustering == "sc":
        print("Spectral clustering ...")
        sc = SpectralClustering(
            n_clusters=n_clusters,
            affinity="nearest_neighbors",
            n_neighbors=n_neighbors,
            eigen_solver="arpack",
            random_state=42,
        ).fit(mat)
        cluster_labels = sc.labels_
        init_nodes_pos = np.empty((0, mat.shape[1]))  # cluster centers
        for x in np.unique(cluster_labels):
            id_cells = np.array(range(mat.shape[0]))[cluster_labels == x]
            init_nodes_pos = np.vstack(
                (init_nodes_pos, np.median(mat[id_cells, :], axis=0))
            )
        epg_nodes_pos = init_nodes_pos
    elif clustering == "kmeans":
        print("K-Means clustering ...")
        kmeans = KMeans(n_clusters=n_clusters, init="k-means++", random_state=42).fit(
            mat
        )
        cluster_labels = kmeans.labels_
        init_nodes_pos = kmeans.cluster_centers_
        epg_nodes_pos = init_nodes_pos
    else:
        print("'" + clustering + "'" + " is not supported")
    adata.obs[clustering] = ["cluster " + str(x) for x in cluster_labels]

    # Minimum Spanning Tree
    print("Calculating minimum spanning tree...")
    D = pairwise_distances(epg_nodes_pos)
    G = nx.from_numpy_matrix(D)
    mst = nx.minimum_spanning_tree(G)
    epg_edges = np.array(mst.edges())

    adata.uns["seed_epg"] = dict()
    adata.uns["seed_epg"]["node_pos"] = epg_nodes_pos
    adata.uns["seed_epg"]["edge"] = epg_edges
    adata.uns["seed_epg"]["params"] = dict(
        obsm=obsm,
        layer=layer,
        clustering=clustering,
        damping=damping,
        pref_perc=pref_perc,
        n_clusters=n_clusters,
        max_n_clusters=max_n_clusters,
        n_neighbors=n_neighbors,
        nb_pct=nb_pct,
    )
    _store_graph_attributes(adata, mat, key="seed_epg")


def _store_graph_attributes(adata, mat, key):
    """ Compute graph attributes and store them in adata.uns[key] """

    G = nx.Graph()
    G.add_edges_from(adata.uns[key]["edge"].tolist(), weight=1)
    mat_conn = nx.to_scipy_sparse_matrix(
        G, nodelist=np.arange(len(adata.uns[key]["node_pos"])), weight="weight"
    )

    # partition points
    node_id, node_dist = elpigraph.src.core.PartitionData(
        X=mat,
        NodePositions=adata.uns[key]["node_pos"],
        MaxBlockSize=len(adata.uns[key]["node_pos"]) ** 4,
        SquaredX=np.sum(mat ** 2, axis=1, keepdims=1),
    )
    # project points onto edges
    dict_proj = elpigraph.src.reporting.project_point_onto_graph(
        X=mat,
        NodePositions=adata.uns[key]["node_pos"],
        Edges=adata.uns[key]["edge"],
        Partition=node_id,
    )

    adata.obs[f"{key}_node_id"] = node_id.flatten()
    adata.obs[f"{key}_node_dist"] = node_dist
    adata.obs[f"{key}_edge_id"] = dict_proj["EdgeID"].astype(int)
    adata.obs[f"{key}_edge_loc"] = dict_proj["ProjectionValues"]

    adata.obsm[f"X_{key}_proj"] = dict_proj["X_projected"]

    adata.uns[key]["conn"] = mat_conn
    adata.uns[key]["edge_len"] = dict_proj["EdgeLen"]


def _get_branch_id(adata, key="epg"):
    """ add adata.obs['branch_id'] """
    # get branches
    net = elpigraph.src.graphs.ConstructGraph({"Edges": [a.uns[key]["edge"]]})
    branches = elpigraph.src.graphs.GetSubGraph(net, "branches")
    _dict_branches = {
        (b[0], b[-1]): b for i, b in enumerate(branches)
    }  # temporary branch node lists (not in order)

    ordered_edges, ordered_nodes = elpigraph.src.supervised.bf_search(
        _dict_branches, root_node=np.where(np.array(net.degree()) == 1)[0][0]
    )
    # create ordered dict
    dict_branches = {}
    for i, e in enumerate(ordered_edges):  # for each branch
        # store branch in order (both the key and the list)
        if e not in _dict_branches:
            dict_branches[e] = _dict_branches[e[::-1]][::-1]
        else:
            dict_branches[e] = _dict_branches[e]

    # disable warning
    pd.options.mode.chained_assignment = None

    point_edges = adata.uns[key]["edge"][adata.obs[f"{key}_edge_id"]]
    a.obs[f"{key}_branch_id"] = ""
    for i, e in enumerate(point_edges):
        for k, v in dict_branches.items():
            if all(np.isin(e, v)):
                adata.obs[f"{key}_branch_id"][i] = k

    # reactivate warning
    pd.options.mode.chained_assignment = "warn"

